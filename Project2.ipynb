{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx.algorithms.bipartite as bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_role = \"https://raw.githubusercontent.com/theoracley/Data620/master/Project2/monero_crime_person_role.csv\"\n",
    "data =pd.read_csv(data_role, header=None)\n",
    "uniqueRoles = set(list(data[0]))\n",
    "uniqueRoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crime =\"https://raw.githubusercontent.com/theoracley/Data620/master/Project2/out.moreno_crime_crime\"\n",
    "#data_role = \"monero_crime_person_role.csv\"\n",
    "crime = pd.read_csv(data_crime, delim_whitespace=True, header=None, skiprows=[0,1], names=['Person', 'Crime'])\n",
    "crime['Rel_Role'] = pd.read_csv(data_role, header=None)\n",
    "crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crime.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(crime.Person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(crime.Crime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking relationship Roles \n",
    "Relations = crime.groupby('Rel_Role')\n",
    "Relations.count()\n",
    "\n",
    "#Relations.count().iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Crimes By Person\n",
    "crimes_per_person = crime.groupby('Person')\n",
    "crimes_per_person.count()[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Distribution (by Person)\n",
    "\n",
    "##### Accordong to the graph below, most Persons were involved in a single crime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histogram [count of Crimes]\n",
    "crime_count = pd.DataFrame({'Crime_Count' : crime.groupby(['Person']).size()}).reset_index()\n",
    "crime_count.iloc[:,1].plot.hist(alpha=0.5, bins=30)\n",
    "plt.xlabel('Crimes', fontsize=20)\n",
    "plt.ylabel('Persons Involved', fontsize=20)\n",
    "plt.title('Histogram (Persons involved by Crime)')\n",
    "plt.grid(True)\n",
    "plt.rcParams['figure.figsize'] = (25, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For every person, let's see how many crimes he/she was involved in, and how many Roles he/she had. We'll add the count information to every row, for quick access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extended_crime = crime\n",
    "#how many Crimes\n",
    "extended_crime['num_crimes'] = extended_crime.groupby(['Person'])['Crime'].transform('count')\n",
    "\n",
    "#how many Roles\n",
    "extended_crime['num_rel_role'] = extended_crime.groupby(['Person', 'Rel_Role'])['Crime'].transform('count')\n",
    "\n",
    "extended_crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's make the records meaningful by adding corresponding person name and sex, since do have data for that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get name data\n",
    "data_name = 'https://raw.githubusercontent.com/theoracley/Data620/master/Project2/ent.moreno_crime_crime.person.name'\n",
    "names = pd.read_csv(data_name, sep='\\t', header=None)\n",
    "\n",
    "#get sex data\n",
    "data_sex = 'https://raw.githubusercontent.com/theoracley/Data620/master/Project2/ent.moreno_crime_crime.person.sex'\n",
    "names['Sex'] = pd.read_csv(data_sex, header=None)\n",
    "\n",
    "names.ix[names.Sex == 1, 'Sex'] = 'M'\n",
    "names.ix[names.Sex == 0, 'Sex'] = 'F'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_crime[\"Sex\"] = \"\"\n",
    "# replacing left nodes (people involved in a crime) with names and adding sex\n",
    "# Right nodes stay as numbers to identify as crimes, not people\n",
    "for i in range(0,len(names)):\n",
    "    extended_crime.ix[extended_crime.Person == i+1, 'Sex'] = names.iloc[i][\"Sex\"]\n",
    "    extended_crime.ix[extended_crime.Person == i+1, 'Person'] = names.iloc[i][0]\n",
    "    \n",
    "extended_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Roles\n",
    "\n",
    "#### There are lot of overlaps. Many suspects are also victims, and many Victimes are also witnesses. The other way is also true.\n",
    "#### For example Katz who is a criminal Pro, has been involved in 18 crimes, 2 victims, once as a witness and 15 times as a suspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grouping suspect, victim and witness nodes in groups, and compute the overlap\n",
    "suspects = set(extended_crime[extended_crime['Rel_Role'] == \"Suspect\"].iloc[:, 0].unique())\n",
    "victims = set(extended_crime[extended_crime['Rel_Role'] == 'Victim'].iloc[:,0].unique())\n",
    "witness = set(extended_crime[extended_crime['Rel_Role'] == \"Witness\"].iloc[:, 0].unique())\n",
    "\n",
    "sus_len = len(suspects)\n",
    "vict_len = len(victims)\n",
    "wit_len = len(witness)\n",
    "\n",
    "sus_vict = len(suspects.intersection(victims))\n",
    "sus_wit = len(suspects.intersection(witness))\n",
    "vict_wit = len(victims.intersection(witness))\n",
    "\n",
    "print('') \n",
    "print('Suspect | Victim | Witness Overlap')\n",
    "print ('----------------------------------')\n",
    "print ('')\n",
    "print ('Suspects:               ', sus_len)\n",
    "print ('Victims:                ', vict_len)\n",
    "print ('Witnesses:              ', wit_len)\n",
    "print ('')\n",
    "print ('Suspect and Victim:      ', sus_vict)\n",
    "print ('Suspect and Witness:     ', sus_wit)\n",
    "print ('Victim and Witness:      ', vict_wit)\n",
    "print ('Victim and Witness:      ', vict_wit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartite Graph\n",
    "#### Monu and I had problems loading the data automatically from pandas frames through networkx API. \n",
    "#### After struggle, we decided to do it manually by using add nodes and add edges methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reloading data in bipartite fashion\n",
    "G2 = nx.Graph()\n",
    "# adding Person nodes\n",
    "for i in range(len(extended_crime)): \n",
    "    G2.add_node(extended_crime.iloc[i][0],\n",
    "                Relation=extended_crime.iloc[i][2],\n",
    "                rel_count=extended_crime.iloc[i][3],\n",
    "                weight=extended_crime.iloc[i][4],\n",
    "                Sex=extended_crime.iloc[i][5],\n",
    "                bipartite=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add crime nodes\n",
    "for i in range(len(extended_crime)): \n",
    "    G2.add_node(extended_crime.iloc[i][1],\n",
    "                bipartite=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add edges\n",
    "# There's an edge between two stations if there was a trip between them.\n",
    "# Edges are weighted by the number of trips\n",
    "for i in range(len(extended_crime)):\n",
    "    G2.add_edge(extended_crime.iloc[i][0], extended_crime.iloc[i][1], weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this graph connected. \n",
    "nx.is_connected(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is it bipartite\n",
    "nx.is_bipartite(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaing a list of top_nodes(people) and bottom_nodes(crime)\n",
    "top_nodes = set(n for n,d in G2.nodes(data=True) if d['bipartite']==1)\n",
    "bottom_nodes = set(G2) - top_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine this!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the info about our graph\n",
    "print(nx.info(G2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first 15 individuals in the dataset\n",
    "print (\"First 15 Persons:\")\n",
    "\n",
    "for i in range(10):\n",
    "    print (' %s    ' % (list(top_nodes)[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph this bipartite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## plot the overall network\n",
    "pos=nx.random_layout(G2) # positions for all nodes\n",
    "\n",
    "# ## elarge=[(u,v) for (u,v,d) in G.edges(data=True) if d['Count'] > 10]\n",
    "# ## esmall=[(u,v) for (u,v,d) in G.edges(data=True) if d['Count'] <= 10]\n",
    "\n",
    "colors=[]\n",
    "for n in dict(G2.degree()).keys():    \n",
    "    if n in dict(G2.degree(top_nodes)).keys():\n",
    "        colors.append('r')\n",
    "    else:\n",
    "        colors.append('b')\n",
    "\n",
    "# # nodes\n",
    "d = G2.degree()\n",
    "nx.draw_networkx_nodes(G2,pos, node_color=colors, node_size=[v*400 for v in dict(d).values()], alpha=0.75)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G2,pos, width=4,alpha=0.5,edge_color='g',style='solid')\n",
    "#nx.draw_networkx_edges(G2,pos,edgelist=esmall, width=2,alpha=0.2,edge_color='b',style='dashed')\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G2, pos, font_size=8, font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person - Bipartite Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Island Moethod and analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the island method after the creation of the weighted bipartite graph. Weights are the number of shared neighbors for an edge. First we isolate the biggest component of the bipartite graph, then we apply the island method and print the threshold level, the size of the graph, and the number of connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SNAFS: get a sorted degree list to obtain topmost nodes\n",
    "def sorted_map(map):\n",
    "    ms = sorted(map.iteritems(), reversed = True) #key=lambda (k,v) : (-v, k))\n",
    "    return ms\n",
    "\n",
    "## Implementing the Island Method to look for important subgroups. ##\n",
    "def trim_edges(g, weight = 1):\n",
    "    # Implements a trimming of the graph edges for the Island Analysis\n",
    "    g2 = nx.Graph()\n",
    "    for f, to, edata in g.edges(data=True):\n",
    "        if edata['weight'] > weight:\n",
    "            g2.add_edge(f,to)\n",
    "    return g2\n",
    "\n",
    "def island_method(g, iterations = 5):\n",
    "    # Iterates through the graph removing edges and returning the number of edges removed and\n",
    "    #  the trimmed graph\n",
    "    weights = [edata['weight'] for f,to,edata in g.edges(data=True)]\n",
    "    mn=int(min(weights))\n",
    "    mx=int(max(weights))\n",
    "    step = int((mx-mn)/iterations)\n",
    "    return [[threshold, trim_edges(g, threshold)] for threshold in range(mn,mx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Island method results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold value of 2 results in a network of 28 Persons and 12 connected components. Of particular interest are suspect nodes connected to Luella Katz, the most-connected suspect in the graph with a degree centrality of 51. Katz is also connected to two other high-degree suspects, Michael Thomas Smith (33 degrees) and Catherine Steiner (29). Both are in the top 10 list of suspects by degree centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC = nx.bipartite.weighted_projected_graph(G2, top_nodes)\n",
    "cc = list(nx.connected_component_subgraphs(PC))[0]\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the Island Analysis on the graph. Will throw an error if the island_method is called with too many steps\n",
    "islands = island_method(cc,3)\n",
    "print ('')\n",
    "print ('Threshold |  Size (Persons)  |  Connected Components')\n",
    "print ('******************************************************')\n",
    "for island in islands:\n",
    "    print('   %d               %2d                   %2d' \n",
    "          %(island[0], len(island[1]), len(list(nx.connected_component_subgraphs(island[1]))))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Graph this at a treshhold = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot created by the island analysis\n",
    "pc = trim_edges(cc, 2)\n",
    "\n",
    "nodecolors=[]\n",
    "for n in dict(pc.degree(top_nodes)).keys():\n",
    "    if n in suspects:\n",
    "        nodecolors.append('g')\n",
    "    elif n in victims:\n",
    "        nodecolors.append('b')\n",
    "    else:\n",
    "        nodecolors.append('y')\n",
    "\n",
    "dpc = pc.degree()\n",
    "nx.draw_random(pc, node_size=[v*1200 for v in dict(dpc).values()], with_labels=True, node_color=nodecolors, \n",
    "               alpha=.25, font_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What about the person Katz. Let's give him a visit and check his ego network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Katz has 51 connections to other people. Those persons are themselves involved as suspects in 40 crimes and victimes in 22 crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luella_katz = nx.ego_graph(PC, 'KatzLuella', radius=1, center=True, undirected=True, distance='weight')\n",
    "\n",
    "nodecolors=[]\n",
    "for n in dict(pc.degree(top_nodes)).keys():\n",
    "    if n in suspects:\n",
    "        nodecolors.append('g')\n",
    "    elif n in victims:\n",
    "        nodecolors.append('b')\n",
    "    else:\n",
    "        nodecolors.append('y')\n",
    "\n",
    "dkatz = luella_katz.degree()\n",
    "nx.draw_random(pc, node_size=[v*1200 for v in dict(dkatz).values()], with_labels=True, node_color=nodecolors, \n",
    "               alpha=.25, font_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luella_katz = extended_crime[extended_crime['Person']=='KatzLuella']\n",
    "katz_connections = pd.DataFrame(cc.edges('KatzLuella'))\n",
    "katz_con = set(katz_connections.iloc[:,1])\n",
    "a = len(katz_con.intersection(victims))\n",
    "b = len(katz_con.intersection(suspects))\n",
    "\n",
    "print ('Luella Katz:')\n",
    "print ('***************************')\n",
    "print ('Victim connections:  ', a)\n",
    "print ('Suspect connections: ', b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crimes - Bipartite Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now take the set of Crime nodes and the relation between them based on the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = nx.bipartite.weighted_projected_graph(G2, bottom_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Crimes - island Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The island analysis identifies a six-node network of crimes. Examination of the crimes shows they all involved Luella Katz and close associates who were suspects. Katz was a witness in crime 110 along with 14 other individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Island Analysis on the graph\n",
    "islands = island_method(CC, iterations = 2)\n",
    "\n",
    "print ('Depth  Crime  Networks')\n",
    "print ('************************')\n",
    "for island in islands:\n",
    "    print(' %d      %3d      %2d' \n",
    "          %(island[0], len(island[1]), len(list(nx.connected_component_subgraphs(island[1])))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Graph This!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 graphs created by the island analysis:\n",
    "wc = trim_edges(CC, 2)\n",
    "dwc = wc.degree()\n",
    "nx.draw(wc, node_size=[v*1400 for v in dict(dwc).values()], with_labels=True, node_color='b', alpha=.25, font_weight='bold', font_size=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table below we take the bipartite weighted graph and examine centrality measures. Per our visual analysis, Luella Katz's heavy involvement is confirmed; she ranks among the top 10 three centrality categories. Katz, Cathering Steiner and Michael Smith all are among the highest in eigenvector centrality â€“ in other words, they are connected to other highly connected suspects and victims. Jenny Willis ranks high in betweenness and degree centrality. A plot of her ego network is below. Inspection shows that Willis and Katz were not involved in any of the same crimes.\n",
    "\n",
    "Crime 110 is of note for high betweeeness centrality: The crime involved 15 witnesses, 2 suspects and one victim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility function to get topmost nodes for each centrality function\n",
    "def get_top_keys(c, top):\n",
    "    #items = dictionary.items()\n",
    "    items= sorted(dictionary.items(), reverse=True, key=lambda x: x[1])\n",
    "    return map(lambda x: x, items[:top])\n",
    "\n",
    "# Betweenness centrality\n",
    "bet_cen = nx.betweenness_centrality(G2)\n",
    "\n",
    "# Degree centrality\n",
    "deg_cen = nx.degree_centrality(G2)\n",
    "\n",
    "# Closeness centrality\n",
    "clo_cen = nx.closeness_centrality(G2)\n",
    "\n",
    "# Eigenvector centrality\n",
    "eig_cen = nx.eigenvector_centrality_numpy(G2)\n",
    "\n",
    "## get the top nodes\n",
    "top_bet_cen = get_top_keys(bet_cen,10)\n",
    "top_clus_cen = get_top_keys(clo_cen,10)\n",
    "top_eig_cen = get_top_keys(eig_cen,10)\n",
    "top_deg_cen = get_top_keys(deg_cen,10)\n",
    "\n",
    "## smush them together to make a comparison chart\n",
    "smush = np.hstack((top_bet_cen, top_clus_cen, top_eig_cen, top_deg_cen))\n",
    "\n",
    "cent_measures=pd.DataFrame(smush, columns=['Node', 'Betweenness', 'Node', 'Closeness', 'Node', \n",
    "                                           'Eigenvector', 'Node', 'Degree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
